---
title: "Homework 3 solutions"
author: "Zichen Shu"
output: github_document

---

```{r setup, include = FALSE}
library(tidyverse)
library(ggplot2)

theme_set(theme_minimal() + theme(legend.position = "botton"))

options(
  ggplot2.continuous.color = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_color_discrete = scale_color_viridis_d
scale_fill_discrete = scale_color_viridis_d

```

## Problem 1

Read in the data.

```{r, message = FALSE}
homicide_df = 
  read_csv("data/homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest" ~ "unsolved",
      disposition == "Closed by arrest" ~ "solved"
    )
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL")
```

Look at this a bit

```{r, message = FALSE}
aggregate_df = 
  homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  )
```

Can I do a prop test for a single city?

```{r}
prop.test(
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved), 
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_total))  %>% 
    broom::tidy()

```

Try to iterate ......

```{r}
results_df = aggregate_df %>% 
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~ prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)
```

```{r, include = FALSE}
results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point()+
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high))+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

results_df %>% 
  arrange(estimate) %>%
  mutate(city_state = fct_inorder(city_state)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point()+
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high))+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) 

```

## Problem 2

```{r, message = FALSE}
path_df = 
  tibble(path = list.files("lda_data"),) %>% 
  mutate(path = str_c("lda_data/", path),
         map_df(path, read_csv)
    ) %>% 
  separate(path, into = c("lda", "subject_id"), sep = "/") %>% 
  separate(subject_id, into = c("subject_id", "csv"), sep = "\\.") %>% 
  select(-lda, -csv) %>% 
  pivot_longer(week_1:week_8, 
               names_to = "week",
               values_to = "value") %>% 
  mutate(week = str_replace(week, "week_", ""))
```


```{r, message = FALSE}
path_df %>% 
  group_by(subject_id) %>% 
  summarize(
    mean = mean(value)
  ) %>% 
  knitr::kable()
  
  
path_df %>% 
  ggplot(aes(x = week, y = value, group = subject_id, color = subject_id))+
  geom_line(alpha = 0.5)+
  theme(legend.position = "right")
```

As we can see from the graph and table, the value of the subjects in the control group is lower than the value of the subjects in the experimental group.

## Problem 3

```{r}
set.seed(3)

sim_t_test = function(samp_size = 30, mu = 0, sigma = 5) {
  
  sim_data = 
    tibble(
      x = rnorm(n = samp_size, mean = mu, sd = sigma)
    )
  
  sim_data = t.test(sim_data) %>%
    broom::tidy() %>%
    mutate(mu_hat = estimate) %>% 
    select(mu_hat, p.value)
  
  sim_data
}


sim_results = 
  tibble(
    mu_true = c(0, 1, 2, 3, 4, 5, 6)
  ) %>%
  mutate(
    output_lists = map(.x = mu_true, ~ rerun(5000, sim_t_test(mu = .x))),
    estimate_df = map(output_lists, bind_rows)
  ) %>% 
  select(-output_lists) %>% 
  unnest(estimate_df)
```

### Part One

plot of the proportion of times the null was rejected vs. true mu
```{r, message = FALSE}
sim_results %>% 
  group_by(mu_true) %>% 
  summarize(
    n_sample = n(),
    n_rejected = sum(p.value < 0.05)
  ) %>% 
  mutate(rejected_prop = n_rejected/n_sample) %>% 
  ggplot(aes(x = mu_true, y = rejected_prop))+
  geom_point(alpha = 0.5) +
  labs(
    x = "True Mu",
    y = "Proportion of Rejection of the Null"
  )
```

When the true mu increases from 0 to 6, the proportion of times when null is rejected increases. This makes sense since the true mu increases while the null hypothesis is mu = 0.

### Part Two

```{r, message = FALSE}
sim_results %>% 
  group_by(mu_true) %>% 
  summarize(mu_hat_mean = mean(mu_hat)) %>% 
  ggplot(aes(x = mu_true, y = mu_hat_mean))+
  geom_point() +
  labs(
    x = "True Mu",
    y = "Average estimate of Mu Hat"
  )

sim_results %>% 
  filter(p.value < 0.05) %>% 
  group_by(mu_true) %>% 
  summarize(mu_hat_mean = mean(mu_hat)) %>% 
  ggplot(aes(x = mu_true, y = mu_hat_mean))+
  geom_point() +
  labs(
    x = "True Mu",
    y = "Average estimate of Mu Hat for Which the Null is Rejected"
  )

sim_results %>% 
  filter(p.value < 0.05) %>%
  group_by(mu_true) %>% 
  summarize(mean_mu_hat = mean(mu_hat)) %>% 
  knitr::kable()
```

When true mu is from 0-2, the average estimate of mu hat only in samples for which the null was rejected is greater than the true mu. This is because 0, 1, 2 are relatively closer to 0, there is going to be a greater proportion of the time when null is not rejected which has value close to 0. So when accounting for the average estimate of mu hat only in samples for which the null was rejected, the mean will be skewed positively.

When true mu is from 4-6, the average estimate of mu hat only in samples for which the null was rejected is approximately equal to the true mu. This makes sense since they are further away from the null. So it is unlikely not to be rejected.















